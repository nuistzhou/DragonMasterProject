---
title: "Dragon Master Project"
output:
  html_notebook: default
  html_document: default
---
This is the final project of the Geoscripting course, period 3, 2016-2017, Wageningen University.  
Authors: Rodrigo Almeida and Ping Zhou  
January 2016  
  
__Main goal:__ Find the best country/region on earth according to a living quality index based on:   
1. Hazard frequency and distribution;  
2. Air pollution;  
3. GDP;  
4. Average year NDVI.  
  
__Warning:__ Running the entire script takes about 2 hours of computation time in the 2 core virtual machine we used. We highly recommend using the terminal.

## Setup  
```{r, include = FALSE}
knitr::read_chunk('main.R')
```
Our project core is located at main.R file. First, we start by setting some environment settings, including he installation of necessary libraries and the import of such libraries. We also source the sub-scripts in the setup section.  
```{r setup, eval=FALSE}
```
## Downloads  
For downloading the necessary datasets, we used two bash scripts called from the main script and a simple download.file function call.   
```{r downloads, eval = FALSE}
```
For the porpuses of the SEDAC data downloaded we used the following wget command.
```{bash, eval = FALSE}
# Example for Drought Hazard dataset
wget -L --user=rodrigoalmeida94 --password=*RmA20071994**** --load-cookies ~/.cookies --save-cookies ~/.cookies --no-directories http://sedac.ciesin.columbia.edu/downloads/data/ndh/ndh-drought-hazard-frequency-distribution/gddrg.zip
# Unzips and places files in the right place
unzip gddrg.zip -d ../data/
rm gddrg.zip
mv ../data/gddrg/gddrg.asc ../data/haz_drought.asc
mv ../data/gddrg/gddrg.prj ../data/haz_drought.prj
rm -r ../data/gddrg
```
For the MODIS NDVI product, we made a for loop that goes through every folder in the DAAC for 2016 and downloads the respective file (0.05 degrees resolution).
```{bash, eval = FALSE}
for i in 01 02 03 04 05 06 07 08 09 10 11 12;
do wget -L --user=rodrigoalmeida94 --password=**** --load-cookies ~/.cookies --save-cookies ~/.cookies -r --no-parent -A '*.hdf' --no-directories -P ../data/http://e4ftl01.cr.usgs.gov/MOLT/MOD13C2.006/2016.$i.01/
done
```
The GECON datasets were available in SEDAC as well, but unfortunately the data had some issues, so we decided to make the raster layer ourselfs from the XLS file provided in the project website.  

## Read files
The process of reading the files into memory is quite straighforward:  
1. Loading all the hazard files with the correct name using a for loop;  
2. Loading the NDVI monthly data, and passing it to the annual_mean function, that returns the annual mean;  
3. Loading the PM2.5 dataset into memory; 
4. Creating the GECON data with the XLS file into two rasters GECON PPP and GECON MER.  
```{r read-files, eval=FALSE, tidy=TRUE}

```

```{r, include=FALSE}
knitr::read_chunk('R/ndvi_annual_mean.R')
```


